<!DOCTYPE html>
<html>

<head>
  <script src="/face-api.09a2c0f8.js"></script>
  <script src="/faceDetectionControls.7e2e2de0.js"></script>
  <link rel="stylesheet" href="/styles.70772303.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
<script src="/styles.70772303.js"></script></head>

<body>

    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div style="position: relative" class="margin">
      <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay="" muted=""></video>
      <canvas id="overlay">
    </canvas></div>


    <select id="selectFaceDetector">
      <option value="ssd_mobilenetv1">SSD Mobilenet V1</option>
      <option value="tiny_face_detector">Tiny Face Detector</option>
      <option value="mtcnn">MTCNN</option>
    </select>
    <label>Select Face Detector</label>

  <script>function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }

function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }

var forwardTimes = [];

function updateTimeStats(timeInMs) {
  forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30);
  var avgTimeInMs = forwardTimes.reduce(function (total, t) {
    return total + t;
  }) / forwardTimes.length;
  $('#time').val("".concat(Math.round(avgTimeInMs), " ms"));
  $('#fps').val("".concat(faceapi.round(1000 / avgTimeInMs)));
}

function onPlay() {
  return _onPlay.apply(this, arguments);
}

function _onPlay() {
  _onPlay = _asyncToGenerator( /*#__PURE__*/regeneratorRuntime.mark(function _callee() {
    var videoEl, options, ts, result, canvas, dims;
    return regeneratorRuntime.wrap(function _callee$(_context) {
      while (1) {
        switch (_context.prev = _context.next) {
          case 0:
            videoEl = $('#inputVideo').get(0);

            if (!(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())) {
              _context.next = 3;
              break;
            }

            return _context.abrupt("return", setTimeout(function () {
              return onPlay();
            }));

          case 3:
            options = getFaceDetectorOptions();
            ts = Date.now();
            _context.next = 7;
            return faceapi.detectSingleFace(videoEl, options);

          case 7:
            result = _context.sent;
            updateTimeStats(Date.now() - ts);

            if (result) {
              canvas = $('#overlay').get(0);
              dims = faceapi.matchDimensions(canvas, videoEl, true);
              faceapi.draw.drawDetections(canvas, faceapi.resizeResults(result, dims));
            }

            setTimeout(function () {
              return onPlay();
            });

          case 11:
          case "end":
            return _context.stop();
        }
      }
    }, _callee);
  }));
  return _onPlay.apply(this, arguments);
}

function run() {
  return _run.apply(this, arguments);
}

function _run() {
  _run = _asyncToGenerator( /*#__PURE__*/regeneratorRuntime.mark(function _callee2() {
    var stream, videoEl;
    return regeneratorRuntime.wrap(function _callee2$(_context2) {
      while (1) {
        switch (_context2.prev = _context2.next) {
          case 0:
            _context2.next = 2;
            return changeFaceDetector(TINY_FACE_DETECTOR);

          case 2:
            changeInputSize(128); // try to access users webcam and stream the images
            // to the video element

            _context2.next = 5;
            return navigator.mediaDevices.getUserMedia({
              video: {}
            });

          case 5:
            stream = _context2.sent;
            videoEl = $('#inputVideo').get(0);
            videoEl.srcObject = stream;

          case 8:
          case "end":
            return _context2.stop();
        }
      }
    }, _callee2);
  }));
  return _run.apply(this, arguments);
}

function updateResults() {}

$(document).ready(function () {
  //renderNavBar('#navbar', 'webcam_face_detection')
  initFaceDetectionControls();
  run();
});</script>
</body>
</html>